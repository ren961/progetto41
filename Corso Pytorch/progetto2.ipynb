{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib as plt\n",
    "import pandas as pd\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from torchvision.datasets.utils import download_url\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download e esplorazione dei dati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./insurance.csv\n"
     ]
    }
   ],
   "source": [
    "DATASET_URL = \"https://gist.github.com/BirajCoder/5f068dfe759c1ea6bdfce9535acdb72d/raw/c84d84e3c80f93be67f6c069cbdc0195ec36acbd/insurance.csv\"\n",
    "DATA_FILENAME = \"insurance.csv\"\n",
    "download_url(DATASET_URL, '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex     bmi  children smoker     region      charges\n",
       "0   19  female  27.900         0    yes  southwest  16884.92400\n",
       "1   18    male  33.770         1     no  southeast   1725.55230\n",
       "2   28    male  33.000         3     no  southeast   4449.46200\n",
       "3   33    male  22.705         0     no  northwest  21984.47061\n",
       "4   32    male  28.880         0     no  northwest   3866.85520"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_raw = pd.read_csv(DATA_FILENAME)\n",
    "dataframe_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "your_name = 'Renato'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customize_dataset(dataframe_raw, rand_str):\n",
    "\n",
    "    dataframe = dataframe_raw.copy(deep = True)         # Crea una copia del dataframe, ponendo deep = True le modifiche apportate non modifica il dataframe originale\n",
    "\n",
    "    # Eliminazione di alcune righe\n",
    "    dataframe = dataframe.sample(int(0.95 * len(dataframe)), random_state = int(ord(rand_str[0])))\n",
    "    # .sample(): Restituisce un numero specificato di righe    /    random_state(): controlla il mescolamento dei dati prima di dividerli\n",
    "\n",
    "    # Scalatura input\n",
    "    dataframe.bmi = dataframe.bmi * ord(rand_str[1])/100.\n",
    "\n",
    "    # Scalatura target\n",
    "\n",
    "    dataframe.charges = dataframe.charges * ord(rand_str[2])/100\n",
    "\n",
    "    # Eliminazione colonne\n",
    "    if ord(rand_str[3]) % 2 == 1:\n",
    "        dataframe = dataframe.drop(['region'], axis=1)\n",
    "\n",
    "    return dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>57</td>\n",
       "      <td>female</td>\n",
       "      <td>30.79995</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>13024.852555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050</th>\n",
       "      <td>44</td>\n",
       "      <td>female</td>\n",
       "      <td>37.32455</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>8825.448995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>58</td>\n",
       "      <td>female</td>\n",
       "      <td>32.14325</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>14968.105625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>24.94700</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>1911.113600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1288</th>\n",
       "      <td>20</td>\n",
       "      <td>male</td>\n",
       "      <td>39.79400</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>42179.022600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      age     sex       bmi  children smoker       charges\n",
       "457    57  female  30.79995         0     no  13024.852555\n",
       "1050   44  female  37.32455         1     no   8825.448995\n",
       "56     58  female  32.14325         2     no  14968.105625\n",
       "311    19  female  24.94700         0     no   1911.113600\n",
       "1288   20    male  39.79400         2    yes  42179.022600"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = customize_dataset(dataframe_raw, your_name)\n",
    "dataframe.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Domanda 1:** quante righe ha **'dataset'**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1271"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_rows = len(dataframe.index)\n",
    "num_rows"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Domanda 2:** quante righe ha 'dataset'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_columns = len(dataframe.columns)\n",
    "num_columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Domanda 3:** Quali sono i titoli delle colonne di input?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age', 'sex', 'bmi', 'children', 'smoker']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_cols = dataframe.columns[:5].tolist()\n",
    "input_cols"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Domanda 4:** Quali colonne non possiedono valori numerici?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sex', 'smoker']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "categorical_cols = dataframe.select_dtypes(exclude = numerics).columns.tolist()\n",
    "categorical_cols"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Domanda 5:** Quali sono i titoli delle colonne di output?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['charges'], dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_cols = dataframe.columns[5:6]\n",
    "output_cols"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Domanda bonus:** minimo, massimo e media dei valori in charges, si può vedere la distribuzione dei valori in un grafico?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il valore massimo è:  70147.470811\n",
      "Il valore minimo è:  1234.06129\n",
      "Il valore medio è:  14433.083083868529\n"
     ]
    }
   ],
   "source": [
    "max_charges = dataframe[\"charges\"].max()\n",
    "min_charges = dataframe[\"charges\"].min()\n",
    "mean_charges = dataframe[\"charges\"].mean()\n",
    "\n",
    "print('Il valore massimo è: ', max_charges)\n",
    "print('Il valore minimo è: ', min_charges)\n",
    "print('Il valore medio è: ', mean_charges)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribuzione dei valori di charges:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Density'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataframe['charges'].plot(kind = 'kde')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparazione dataset per il training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per poter eserguire il training abbiamo bisogno di avere dei tensori, quindi faremo una trasformazione da pandas a pytorch: **Pandas --> NumPy --> Pytorch**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passaggio da dataframe ad arry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_to_arrays(dataframe):\n",
    "    dataframe1 = dataframe.copy(deep = True)        #copia dataframe\n",
    "\n",
    "    # Conversione delle colonne non numeriche a numeriche\n",
    "    for col in categorical_cols:\n",
    "        dataframe1[col] = dataframe1[col].astype('category').cat.codes      # Categorizza attraverso codici numerici\n",
    "\n",
    "    # Estrazione di input e output sotto forma di array numPy\n",
    "    inputs_array = dataframe1[input_cols].to_numpy()\n",
    "    targets_array = dataframe1[output_cols].to_numpy()\n",
    "\n",
    "    return inputs_array, targets_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[57.     ,  0.     , 30.79995,  0.     ,  0.     ],\n",
       "        [44.     ,  0.     , 37.32455,  1.     ,  0.     ],\n",
       "        [58.     ,  0.     , 32.14325,  2.     ,  0.     ],\n",
       "        ...,\n",
       "        [59.     ,  0.     , 35.148  ,  2.     ,  0.     ],\n",
       "        [41.     ,  1.     , 29.088  ,  1.     ,  0.     ],\n",
       "        [36.     ,  0.     , 30.3202 ,  0.     ,  0.     ]]),\n",
       " array([[13024.852555],\n",
       "        [ 8825.448995],\n",
       "        [14968.105625],\n",
       "        ...,\n",
       "        [40601.668833],\n",
       "        [ 6910.4585  ],\n",
       "        [ 5799.39338 ]]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_array, targets_array = dataframe_to_arrays(dataframe)\n",
    "inputs_array, targets_array"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Domanda 6:** convertire array numpy in tensori PyTorch (NB! Fare attenzione che siano float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.from_numpy(inputs_array).to(torch.float32)\n",
    "targets = torch.from_numpy(targets_array).to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.float32, torch.float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.dtype, targets.dtype     # Verifica tipologia dati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1271\n"
     ]
    }
   ],
   "source": [
    "dataset = TensorDataset(inputs, targets)\n",
    "print(len(dataset))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Domanda 7:** Scegliere un numero tra 0.1 e 0.2 per determinare la frazione di dati che verranno usati per creare un validation set, quindi usare random_split per creare training e validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensione validation test:  254\n",
      "Dimensione training test:  1017\n"
     ]
    }
   ],
   "source": [
    "val_percent = 0.2\n",
    "val_size = int (num_rows * val_percent)\n",
    "print('Dimensione validation test: ', val_size)\n",
    "train_size = num_rows - val_size\n",
    "print('Dimensione training test: ', train_size)\n",
    "\n",
    "train_ds, val_ds = random_split(dataset, [train_size, val_size])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Domanda 8:** Scegliere una dimensione di lotto per il data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_ds, batch_size, shuffle = True)\n",
    "val_loader = DataLoader(val_ds, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  tensor([[40.0000,  0.0000, 22.4422,  2.0000,  1.0000],\n",
      "        [43.0000,  0.0000, 25.5227,  1.0000,  1.0000],\n",
      "        [45.0000,  0.0000, 27.9214,  1.0000,  0.0000],\n",
      "        [26.0000,  1.0000, 17.8467,  0.0000,  0.0000],\n",
      "        [59.0000,  1.0000, 25.7146,  1.0000,  0.0000],\n",
      "        [21.0000,  1.0000, 31.4110,  0.0000,  0.0000],\n",
      "        [30.0000,  1.0000, 35.8853,  0.0000,  1.0000],\n",
      "        [29.0000,  1.0000, 30.0324,  2.0000,  0.0000]])\n",
      "targets:  tensor([[21388.6914],\n",
      "        [23948.4766],\n",
      "        [31174.2070],\n",
      "        [ 2949.0442],\n",
      "        [14205.3916],\n",
      "        [ 1678.9432],\n",
      "        [40645.2812],\n",
      "        [19973.6641]])\n"
     ]
    }
   ],
   "source": [
    "for xb, yb in train_loader:\n",
    "    print('inputs: ', xb)\n",
    "    print('targets: ', yb)\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creare un modello di regressione lineare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = len(input_cols)\n",
    "output_size = len(output_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InsuranceModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        out = self.linear(xb)\n",
    "        return out\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        inputs, targets = batch\n",
    "        out = self(inputs)   \n",
    "\n",
    "        loss = F.l1_loss(out, targets)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        inputs, targets = batch\n",
    "        out = self(inputs)  \n",
    "        loss = F.l1_loss(out, targets)\n",
    "        return {'val_loss': loss.detach()}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()\n",
    "        return {'val_loss': epoch_loss.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result, num_epochs):\n",
    "        if (epoch+1) % 20 == 0 or epoch == num_epochs-1:\n",
    "            print(\"Epoch [{}], val_loss: {:.4f}\".format(epoch+1, result['val_loss']))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = InsuranceModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x7fd7905645f0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.1712, -0.4165, -0.1237, -0.1863,  0.1933]], requires_grad=True)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.linear.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.2033], requires_grad=True)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.linear.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[49.0000,  0.0000, 22.8361,  1.0000,  0.0000],\n",
      "        [28.0000,  1.0000, 27.2498,  2.0000,  0.0000],\n",
      "        [51.0000,  0.0000, 41.0666,  0.0000,  0.0000],\n",
      "        [39.0000,  1.0000, 24.7551,  2.0000,  0.0000],\n",
      "        [19.0000,  0.0000, 29.1890,  0.0000,  0.0000],\n",
      "        [35.0000,  1.0000, 29.1890,  3.0000,  0.0000],\n",
      "        [31.0000,  1.0000, 31.3757,  3.0000,  0.0000],\n",
      "        [36.0000,  0.0000, 30.3202,  0.0000,  0.0000]]), tensor([[10523.6904],\n",
      "        [ 4878.6035],\n",
      "        [10863.2480],\n",
      "        [ 7381.2109],\n",
      "        [ 1917.5354],\n",
      "        [ 6519.5308],\n",
      "        [ 5967.5259],\n",
      "        [ 5799.3936]])]\n"
     ]
    }
   ],
   "source": [
    "print(next(iter(val_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.1712, -0.4165, -0.1237, -0.1863,  0.1933]], requires_grad=True)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.linear.weight"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader):\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(), lr)\n",
    "    for epoch in range(epochs):\n",
    "        # Training Phase \n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        # Validation phase\n",
    "        result = evaluate(model, val_loader)\n",
    "        model.epoch_end(epoch, result, epochs)\n",
    "        history.append(result)\n",
    "    return history"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Domanda 9:** usa la funzione evaluate per calcolare la perdita del validation set prima del training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_loss': 13276.0400390625}\n"
     ]
    }
   ],
   "source": [
    "result = evaluate(model, val_loader)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20], val_loss: 6466.1978\n",
      "Epoch [40], val_loss: 6367.3857\n",
      "Epoch [60], val_loss: 6341.3721\n",
      "Epoch [80], val_loss: 6341.1133\n",
      "Epoch [100], val_loss: 6295.9697\n",
      "Epoch [120], val_loss: 6276.3862\n",
      "Epoch [140], val_loss: 6264.3877\n",
      "Epoch [160], val_loss: 6285.1675\n",
      "Epoch [180], val_loss: 6237.2427\n",
      "Epoch [200], val_loss: 6228.7402\n",
      "Epoch [220], val_loss: 6253.1426\n",
      "Epoch [240], val_loss: 6242.7490\n",
      "Epoch [260], val_loss: 6232.6748\n",
      "Epoch [280], val_loss: 6190.4375\n",
      "Epoch [300], val_loss: 6190.2378\n",
      "Epoch [320], val_loss: 6247.3779\n",
      "Epoch [340], val_loss: 6151.9937\n",
      "Epoch [360], val_loss: 6140.5908\n",
      "Epoch [380], val_loss: 6209.0698\n",
      "Epoch [400], val_loss: 6121.5430\n",
      "Epoch [420], val_loss: 6185.5732\n",
      "Epoch [440], val_loss: 6114.7417\n",
      "Epoch [460], val_loss: 6197.1191\n",
      "Epoch [480], val_loss: 6112.7295\n",
      "Epoch [500], val_loss: 6112.8979\n",
      "Epoch [520], val_loss: 6083.0166\n",
      "Epoch [540], val_loss: 6057.6387\n",
      "Epoch [560], val_loss: 6058.3677\n",
      "Epoch [580], val_loss: 6041.8652\n",
      "Epoch [600], val_loss: 6015.9541\n",
      "Epoch [620], val_loss: 6080.7861\n",
      "Epoch [640], val_loss: 5999.6919\n",
      "Epoch [660], val_loss: 5990.5742\n",
      "Epoch [680], val_loss: 6007.7285\n",
      "Epoch [700], val_loss: 6101.1743\n",
      "Epoch [720], val_loss: 5958.6143\n",
      "Epoch [740], val_loss: 5997.2993\n",
      "Epoch [760], val_loss: 6018.3892\n",
      "Epoch [780], val_loss: 5930.2632\n",
      "Epoch [800], val_loss: 5921.8394\n",
      "Epoch [820], val_loss: 5981.8213\n",
      "Epoch [840], val_loss: 6106.0928\n",
      "Epoch [860], val_loss: 5903.3091\n",
      "Epoch [880], val_loss: 5974.2544\n",
      "Epoch [900], val_loss: 5876.3159\n",
      "Epoch [920], val_loss: 5941.4658\n",
      "Epoch [940], val_loss: 5889.2197\n",
      "Epoch [960], val_loss: 5919.5708\n",
      "Epoch [980], val_loss: 5837.5840\n",
      "Epoch [1000], val_loss: 5901.1294\n",
      "Epoch [1020], val_loss: 5815.5332\n",
      "Epoch [1040], val_loss: 5852.2700\n",
      "Epoch [1060], val_loss: 5802.5464\n",
      "Epoch [1080], val_loss: 5923.3320\n",
      "Epoch [1100], val_loss: 5861.0664\n",
      "Epoch [1120], val_loss: 5768.5044\n",
      "Epoch [1140], val_loss: 5821.4858\n",
      "Epoch [1160], val_loss: 5752.9766\n",
      "Epoch [1180], val_loss: 5765.0073\n",
      "Epoch [1200], val_loss: 5760.4873\n",
      "Epoch [1220], val_loss: 5723.9829\n",
      "Epoch [1240], val_loss: 5715.5308\n",
      "Epoch [1260], val_loss: 5771.1494\n",
      "Epoch [1280], val_loss: 5702.7085\n",
      "Epoch [1300], val_loss: 5735.0366\n",
      "Epoch [1320], val_loss: 5710.9341\n",
      "Epoch [1340], val_loss: 5672.3486\n",
      "Epoch [1360], val_loss: 5675.0527\n",
      "Epoch [1380], val_loss: 5681.3105\n",
      "Epoch [1400], val_loss: 5705.8340\n",
      "Epoch [1420], val_loss: 5687.5156\n",
      "Epoch [1440], val_loss: 5674.6143\n",
      "Epoch [1460], val_loss: 5658.6035\n",
      "Epoch [1480], val_loss: 5625.9966\n",
      "Epoch [1500], val_loss: 5597.4595\n",
      "Epoch [1520], val_loss: 5683.9712\n",
      "Epoch [1540], val_loss: 5664.4824\n",
      "Epoch [1560], val_loss: 5566.0229\n",
      "Epoch [1580], val_loss: 5601.8491\n",
      "Epoch [1600], val_loss: 5555.6938\n",
      "Epoch [1620], val_loss: 5642.9438\n",
      "Epoch [1640], val_loss: 5540.4663\n",
      "Epoch [1660], val_loss: 5530.3389\n",
      "Epoch [1680], val_loss: 5514.9370\n",
      "Epoch [1700], val_loss: 5589.1587\n",
      "Epoch [1720], val_loss: 5612.0303\n",
      "Epoch [1740], val_loss: 5514.1455\n",
      "Epoch [1760], val_loss: 5479.9053\n",
      "Epoch [1780], val_loss: 5480.2300\n",
      "Epoch [1800], val_loss: 5454.9600\n",
      "Epoch [1820], val_loss: 5459.3223\n",
      "Epoch [1840], val_loss: 5436.4443\n",
      "Epoch [1860], val_loss: 5429.5317\n",
      "Epoch [1880], val_loss: 5429.2388\n",
      "Epoch [1900], val_loss: 5439.5605\n",
      "Epoch [1920], val_loss: 5450.6318\n",
      "Epoch [1940], val_loss: 5391.1841\n",
      "Epoch [1960], val_loss: 5383.0088\n",
      "Epoch [1980], val_loss: 5403.2549\n",
      "Epoch [2000], val_loss: 5365.7441\n",
      "Epoch [2020], val_loss: 5442.6504\n",
      "Epoch [2040], val_loss: 5348.4653\n",
      "Epoch [2060], val_loss: 5354.9141\n",
      "Epoch [2080], val_loss: 5435.3174\n",
      "Epoch [2100], val_loss: 5384.3848\n",
      "Epoch [2120], val_loss: 5311.2603\n",
      "Epoch [2140], val_loss: 5314.8242\n",
      "Epoch [2160], val_loss: 5307.8364\n",
      "Epoch [2180], val_loss: 5290.0361\n",
      "Epoch [2200], val_loss: 5283.0981\n",
      "Epoch [2220], val_loss: 5313.6138\n",
      "Epoch [2240], val_loss: 5258.4209\n",
      "Epoch [2260], val_loss: 5247.3213\n",
      "Epoch [2280], val_loss: 5249.9512\n",
      "Epoch [2300], val_loss: 5232.3467\n",
      "Epoch [2320], val_loss: 5312.2505\n",
      "Epoch [2340], val_loss: 5220.4731\n",
      "Epoch [2360], val_loss: 5205.9819\n",
      "Epoch [2380], val_loss: 5206.9404\n",
      "Epoch [2400], val_loss: 5228.0117\n",
      "Epoch [2420], val_loss: 5226.2515\n",
      "Epoch [2440], val_loss: 5167.8994\n",
      "Epoch [2460], val_loss: 5155.9150\n",
      "Epoch [2480], val_loss: 5226.4878\n",
      "Epoch [2500], val_loss: 5163.7583\n",
      "Epoch [2520], val_loss: 5166.8081\n",
      "Epoch [2540], val_loss: 5292.0234\n",
      "Epoch [2560], val_loss: 5117.4590\n",
      "Epoch [2580], val_loss: 5219.9531\n",
      "Epoch [2600], val_loss: 5187.2393\n",
      "Epoch [2620], val_loss: 5143.9248\n",
      "Epoch [2640], val_loss: 5100.0605\n",
      "Epoch [2660], val_loss: 5080.8623\n",
      "Epoch [2680], val_loss: 5060.5879\n",
      "Epoch [2700], val_loss: 5055.9150\n",
      "Epoch [2720], val_loss: 5089.8330\n",
      "Epoch [2740], val_loss: 5056.8994\n",
      "Epoch [2760], val_loss: 5020.9272\n",
      "Epoch [2780], val_loss: 5014.2417\n",
      "Epoch [2800], val_loss: 5101.4150\n",
      "Epoch [2820], val_loss: 5003.6875\n",
      "Epoch [2840], val_loss: 4991.2866\n",
      "Epoch [2860], val_loss: 5095.5938\n",
      "Epoch [2880], val_loss: 4968.0713\n",
      "Epoch [2900], val_loss: 4959.3003\n",
      "Epoch [2920], val_loss: 4957.9150\n",
      "Epoch [2940], val_loss: 4955.7627\n",
      "Epoch [2960], val_loss: 4962.9219\n",
      "Epoch [2980], val_loss: 4923.1548\n",
      "Epoch [3000], val_loss: 4962.9126\n",
      "Epoch [3020], val_loss: 4906.0503\n",
      "Epoch [3040], val_loss: 4897.7485\n",
      "Epoch [3060], val_loss: 5036.4375\n",
      "Epoch [3080], val_loss: 4884.4541\n",
      "Epoch [3100], val_loss: 4964.1372\n",
      "Epoch [3120], val_loss: 4930.2461\n",
      "Epoch [3140], val_loss: 4854.1748\n",
      "Epoch [3160], val_loss: 4842.7114\n",
      "Epoch [3180], val_loss: 4932.5366\n",
      "Epoch [3200], val_loss: 4891.1348\n",
      "Epoch [3220], val_loss: 4831.5718\n",
      "Epoch [3240], val_loss: 4853.7925\n",
      "Epoch [3260], val_loss: 4840.7251\n",
      "Epoch [3280], val_loss: 4879.7007\n",
      "Epoch [3300], val_loss: 4845.3589\n",
      "Epoch [3320], val_loss: 4840.0605\n",
      "Epoch [3340], val_loss: 4811.6567\n",
      "Epoch [3360], val_loss: 4859.7402\n",
      "Epoch [3380], val_loss: 4776.0005\n",
      "Epoch [3400], val_loss: 4782.8574\n",
      "Epoch [3420], val_loss: 4817.2480\n",
      "Epoch [3440], val_loss: 4719.2515\n",
      "Epoch [3460], val_loss: 4732.7119\n",
      "Epoch [3480], val_loss: 4717.4102\n",
      "Epoch [3500], val_loss: 4692.8921\n",
      "Epoch [3520], val_loss: 4731.7627\n",
      "Epoch [3540], val_loss: 4675.6099\n",
      "Epoch [3560], val_loss: 4665.8979\n",
      "Epoch [3580], val_loss: 4785.6133\n",
      "Epoch [3600], val_loss: 4648.8232\n",
      "Epoch [3620], val_loss: 4676.4302\n",
      "Epoch [3640], val_loss: 4634.8516\n",
      "Epoch [3660], val_loss: 4652.7065\n",
      "Epoch [3680], val_loss: 4677.2314\n",
      "Epoch [3700], val_loss: 4646.2666\n",
      "Epoch [3720], val_loss: 4602.5527\n",
      "Epoch [3740], val_loss: 4674.2261\n",
      "Epoch [3760], val_loss: 4581.3335\n",
      "Epoch [3780], val_loss: 4578.2441\n",
      "Epoch [3800], val_loss: 4578.8066\n",
      "Epoch [3820], val_loss: 4556.9287\n",
      "Epoch [3840], val_loss: 4546.8325\n",
      "Epoch [3860], val_loss: 4535.6411\n",
      "Epoch [3880], val_loss: 4527.4780\n",
      "Epoch [3900], val_loss: 4674.2905\n",
      "Epoch [3920], val_loss: 4525.0903\n",
      "Epoch [3940], val_loss: 4522.5107\n",
      "Epoch [3960], val_loss: 4542.6265\n",
      "Epoch [3980], val_loss: 4484.3711\n",
      "Epoch [4000], val_loss: 4476.1812\n",
      "Epoch [4020], val_loss: 4469.5952\n",
      "Epoch [4040], val_loss: 4563.6177\n",
      "Epoch [4060], val_loss: 4451.3457\n",
      "Epoch [4080], val_loss: 4476.7539\n",
      "Epoch [4100], val_loss: 4470.7510\n",
      "Epoch [4120], val_loss: 4437.4839\n",
      "Epoch [4140], val_loss: 4466.2080\n",
      "Epoch [4160], val_loss: 4464.5303\n",
      "Epoch [4180], val_loss: 4492.6382\n",
      "Epoch [4200], val_loss: 4555.8755\n",
      "Epoch [4220], val_loss: 4470.1387\n",
      "Epoch [4240], val_loss: 4376.7324\n",
      "Epoch [4260], val_loss: 4383.4756\n",
      "Epoch [4280], val_loss: 4498.8491\n",
      "Epoch [4300], val_loss: 4387.3584\n",
      "Epoch [4320], val_loss: 4350.4072\n",
      "Epoch [4340], val_loss: 4371.1934\n",
      "Epoch [4360], val_loss: 4330.1079\n",
      "Epoch [4380], val_loss: 4320.9517\n",
      "Epoch [4400], val_loss: 4320.0527\n",
      "Epoch [4420], val_loss: 4304.6035\n",
      "Epoch [4440], val_loss: 4297.7637\n",
      "Epoch [4460], val_loss: 4314.7148\n",
      "Epoch [4480], val_loss: 4283.6255\n",
      "Epoch [4500], val_loss: 4306.5659\n",
      "Epoch [4520], val_loss: 4281.2954\n",
      "Epoch [4540], val_loss: 4258.8340\n",
      "Epoch [4560], val_loss: 4312.0220\n",
      "Epoch [4580], val_loss: 4278.9863\n",
      "Epoch [4600], val_loss: 4384.6616\n",
      "Epoch [4620], val_loss: 4326.1182\n",
      "Epoch [4640], val_loss: 4249.0288\n",
      "Epoch [4660], val_loss: 4270.3594\n",
      "Epoch [4680], val_loss: 4321.5317\n",
      "Epoch [4700], val_loss: 4250.0439\n",
      "Epoch [4720], val_loss: 4315.2759\n",
      "Epoch [4740], val_loss: 4190.6357\n",
      "Epoch [4760], val_loss: 4270.4160\n",
      "Epoch [4780], val_loss: 4177.6582\n",
      "Epoch [4800], val_loss: 4171.3516\n",
      "Epoch [4820], val_loss: 4160.1396\n",
      "Epoch [4840], val_loss: 4220.3574\n",
      "Epoch [4860], val_loss: 4152.9829\n",
      "Epoch [4880], val_loss: 4139.5947\n",
      "Epoch [4900], val_loss: 4165.9653\n",
      "Epoch [4920], val_loss: 4144.0376\n",
      "Epoch [4940], val_loss: 4119.5923\n",
      "Epoch [4960], val_loss: 4221.0083\n",
      "Epoch [4980], val_loss: 4127.2129\n",
      "Epoch [5000], val_loss: 4102.0664\n",
      "Epoch [5020], val_loss: 4094.3020\n",
      "Epoch [5040], val_loss: 4092.3613\n",
      "Epoch [5060], val_loss: 4082.3884\n",
      "Epoch [5080], val_loss: 4101.1484\n",
      "Epoch [5100], val_loss: 4089.1284\n",
      "Epoch [5120], val_loss: 4091.3101\n"
     ]
    }
   ],
   "source": [
    "epochs = 5120\n",
    "lr = 0.1\n",
    "history1 = fit(epochs, lr, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20], val_loss: 4086.4395\n",
      "Epoch [40], val_loss: 4085.2065\n",
      "Epoch [60], val_loss: 4063.3074\n",
      "Epoch [80], val_loss: 4163.5933\n",
      "Epoch [100], val_loss: 4125.0181\n",
      "Epoch [120], val_loss: 4040.4165\n",
      "Epoch [140], val_loss: 4172.0986\n",
      "Epoch [160], val_loss: 4024.5198\n",
      "Epoch [180], val_loss: 4069.4238\n",
      "Epoch [200], val_loss: 4062.2090\n",
      "Epoch [220], val_loss: 4055.7915\n",
      "Epoch [240], val_loss: 4012.2139\n",
      "Epoch [260], val_loss: 4002.0811\n",
      "Epoch [280], val_loss: 3995.4575\n",
      "Epoch [300], val_loss: 3997.7305\n",
      "Epoch [320], val_loss: 4025.3843\n",
      "Epoch [340], val_loss: 3982.7563\n",
      "Epoch [360], val_loss: 4079.0999\n",
      "Epoch [380], val_loss: 3972.9517\n",
      "Epoch [400], val_loss: 3968.5725\n",
      "Epoch [420], val_loss: 4070.0334\n",
      "Epoch [440], val_loss: 3964.0298\n",
      "Epoch [460], val_loss: 3989.2783\n",
      "Epoch [480], val_loss: 3975.8706\n",
      "Epoch [500], val_loss: 3966.5020\n",
      "Epoch [520], val_loss: 3956.9287\n",
      "Epoch [540], val_loss: 3945.9292\n",
      "Epoch [560], val_loss: 3969.9724\n",
      "Epoch [580], val_loss: 3998.2285\n",
      "Epoch [600], val_loss: 4034.9048\n",
      "Epoch [620], val_loss: 3932.0891\n",
      "Epoch [640], val_loss: 3937.4473\n",
      "Epoch [660], val_loss: 3931.2324\n",
      "Epoch [680], val_loss: 4110.3223\n",
      "Epoch [700], val_loss: 3928.4783\n",
      "Epoch [720], val_loss: 3959.6958\n",
      "Epoch [740], val_loss: 3956.8647\n",
      "Epoch [760], val_loss: 3950.5234\n",
      "Epoch [780], val_loss: 3930.6880\n",
      "Epoch [800], val_loss: 3907.7856\n",
      "Epoch [820], val_loss: 3903.9607\n",
      "Epoch [840], val_loss: 3957.7942\n",
      "Epoch [860], val_loss: 3927.1345\n",
      "Epoch [880], val_loss: 3896.5430\n",
      "Epoch [900], val_loss: 3896.5520\n",
      "Epoch [920], val_loss: 3960.9841\n",
      "Epoch [940], val_loss: 3903.0461\n",
      "Epoch [960], val_loss: 3887.2275\n",
      "Epoch [980], val_loss: 3907.6038\n",
      "Epoch [1000], val_loss: 3886.8965\n",
      "Epoch [1020], val_loss: 3902.5432\n",
      "Epoch [1040], val_loss: 3878.5515\n",
      "Epoch [1060], val_loss: 3889.0205\n",
      "Epoch [1080], val_loss: 4027.8831\n",
      "Epoch [1100], val_loss: 3872.4043\n",
      "Epoch [1120], val_loss: 3880.5090\n",
      "Epoch [1140], val_loss: 3870.8618\n",
      "Epoch [1160], val_loss: 3908.1216\n",
      "Epoch [1180], val_loss: 3898.1716\n",
      "Epoch [1200], val_loss: 3865.5542\n",
      "Epoch [1220], val_loss: 3887.7815\n",
      "Epoch [1240], val_loss: 3863.8145\n",
      "Epoch [1260], val_loss: 3904.8499\n",
      "Epoch [1280], val_loss: 3890.5083\n",
      "Epoch [1300], val_loss: 3870.5002\n",
      "Epoch [1320], val_loss: 3861.0181\n",
      "Epoch [1340], val_loss: 3861.9734\n",
      "Epoch [1360], val_loss: 3850.1013\n",
      "Epoch [1380], val_loss: 3919.3889\n",
      "Epoch [1400], val_loss: 3957.6748\n",
      "Epoch [1420], val_loss: 3848.7734\n",
      "Epoch [1440], val_loss: 3927.2739\n",
      "Epoch [1460], val_loss: 3892.6577\n",
      "Epoch [1480], val_loss: 3850.0747\n",
      "Epoch [1500], val_loss: 3870.9971\n",
      "Epoch [1520], val_loss: 3882.4131\n",
      "Epoch [1540], val_loss: 3885.7664\n",
      "Epoch [1560], val_loss: 3837.8835\n",
      "Epoch [1580], val_loss: 3879.9817\n",
      "Epoch [1600], val_loss: 3845.5664\n",
      "Epoch [1620], val_loss: 3872.0671\n",
      "Epoch [1640], val_loss: 3916.4524\n",
      "Epoch [1660], val_loss: 3876.2070\n",
      "Epoch [1680], val_loss: 3842.0200\n",
      "Epoch [1700], val_loss: 3836.9897\n",
      "Epoch [1720], val_loss: 3837.4121\n",
      "Epoch [1740], val_loss: 3911.4851\n",
      "Epoch [1760], val_loss: 3829.5654\n",
      "Epoch [1780], val_loss: 3842.7979\n",
      "Epoch [1800], val_loss: 3858.1287\n",
      "Epoch [1820], val_loss: 3829.4644\n",
      "Epoch [1840], val_loss: 3957.5742\n",
      "Epoch [1860], val_loss: 3827.5298\n",
      "Epoch [1880], val_loss: 3860.8921\n",
      "Epoch [1900], val_loss: 3827.7761\n",
      "Epoch [1920], val_loss: 3885.2090\n",
      "Epoch [1940], val_loss: 3892.8079\n",
      "Epoch [1960], val_loss: 3837.6038\n",
      "Epoch [1980], val_loss: 3825.0454\n",
      "Epoch [2000], val_loss: 3983.2480\n",
      "Epoch [2020], val_loss: 3828.2915\n",
      "Epoch [2040], val_loss: 3851.3899\n",
      "Epoch [2060], val_loss: 4000.8120\n",
      "Epoch [2080], val_loss: 3838.3250\n",
      "Epoch [2100], val_loss: 3826.5837\n",
      "Epoch [2120], val_loss: 3827.5681\n",
      "Epoch [2140], val_loss: 3834.6384\n",
      "Epoch [2160], val_loss: 3833.5107\n",
      "Epoch [2180], val_loss: 3821.8821\n",
      "Epoch [2200], val_loss: 3868.5325\n",
      "Epoch [2220], val_loss: 3822.3896\n",
      "Epoch [2240], val_loss: 3863.6848\n",
      "Epoch [2260], val_loss: 3820.9600\n",
      "Epoch [2280], val_loss: 3824.1538\n",
      "Epoch [2300], val_loss: 3830.2524\n",
      "Epoch [2320], val_loss: 3821.1616\n",
      "Epoch [2340], val_loss: 3830.1851\n",
      "Epoch [2360], val_loss: 3933.1504\n",
      "Epoch [2380], val_loss: 3879.7100\n",
      "Epoch [2400], val_loss: 3870.8201\n",
      "Epoch [2420], val_loss: 3952.4504\n",
      "Epoch [2440], val_loss: 3824.5103\n",
      "Epoch [2460], val_loss: 3821.6199\n",
      "Epoch [2480], val_loss: 3818.1292\n",
      "Epoch [2500], val_loss: 3834.5637\n",
      "Epoch [2520], val_loss: 3816.4641\n",
      "Epoch [2540], val_loss: 3815.9824\n",
      "Epoch [2560], val_loss: 3847.6448\n",
      "Epoch [2580], val_loss: 3830.7778\n",
      "Epoch [2600], val_loss: 3898.7148\n",
      "Epoch [2620], val_loss: 3820.5999\n",
      "Epoch [2640], val_loss: 3828.0981\n",
      "Epoch [2660], val_loss: 3813.4473\n",
      "Epoch [2680], val_loss: 3815.9084\n",
      "Epoch [2700], val_loss: 3900.2808\n",
      "Epoch [2720], val_loss: 3815.5349\n",
      "Epoch [2740], val_loss: 3813.7871\n",
      "Epoch [2760], val_loss: 3829.2786\n",
      "Epoch [2780], val_loss: 3859.4951\n",
      "Epoch [2800], val_loss: 3815.4707\n",
      "Epoch [2820], val_loss: 3878.1865\n",
      "Epoch [2840], val_loss: 3907.8071\n",
      "Epoch [2860], val_loss: 3810.7942\n",
      "Epoch [2880], val_loss: 3825.6785\n",
      "Epoch [2900], val_loss: 3843.9958\n",
      "Epoch [2920], val_loss: 3819.2930\n",
      "Epoch [2940], val_loss: 3810.2029\n",
      "Epoch [2960], val_loss: 3811.6709\n",
      "Epoch [2980], val_loss: 3838.4502\n",
      "Epoch [3000], val_loss: 3877.4458\n",
      "Epoch [3020], val_loss: 3851.4492\n",
      "Epoch [3040], val_loss: 3807.9395\n",
      "Epoch [3060], val_loss: 3828.1318\n",
      "Epoch [3080], val_loss: 3854.0405\n",
      "Epoch [3100], val_loss: 3810.7642\n",
      "Epoch [3120], val_loss: 3834.7766\n",
      "Epoch [3140], val_loss: 3813.0967\n",
      "Epoch [3160], val_loss: 3871.3923\n",
      "Epoch [3180], val_loss: 3828.6321\n",
      "Epoch [3200], val_loss: 3845.4683\n",
      "Epoch [3220], val_loss: 3807.0698\n",
      "Epoch [3240], val_loss: 3809.9639\n",
      "Epoch [3260], val_loss: 3808.6514\n",
      "Epoch [3280], val_loss: 3810.7236\n",
      "Epoch [3300], val_loss: 3812.7590\n",
      "Epoch [3320], val_loss: 3960.4243\n",
      "Epoch [3340], val_loss: 3810.4082\n",
      "Epoch [3360], val_loss: 3806.1401\n",
      "Epoch [3380], val_loss: 3852.1482\n",
      "Epoch [3400], val_loss: 3806.5232\n",
      "Epoch [3420], val_loss: 3815.2693\n",
      "Epoch [3440], val_loss: 3884.1958\n",
      "Epoch [3460], val_loss: 3862.1489\n",
      "Epoch [3480], val_loss: 3851.9021\n",
      "Epoch [3500], val_loss: 3815.0623\n",
      "Epoch [3520], val_loss: 3956.0161\n",
      "Epoch [3540], val_loss: 3883.9380\n",
      "Epoch [3560], val_loss: 3803.7881\n",
      "Epoch [3580], val_loss: 3812.5786\n",
      "Epoch [3600], val_loss: 3823.2261\n",
      "Epoch [3620], val_loss: 3804.1865\n",
      "Epoch [3640], val_loss: 3803.0049\n",
      "Epoch [3660], val_loss: 3845.2771\n",
      "Epoch [3680], val_loss: 3812.2661\n",
      "Epoch [3700], val_loss: 3837.2773\n",
      "Epoch [3720], val_loss: 3809.1516\n",
      "Epoch [3740], val_loss: 3981.4570\n",
      "Epoch [3760], val_loss: 3810.9612\n",
      "Epoch [3780], val_loss: 3820.2117\n",
      "Epoch [3800], val_loss: 3882.7573\n",
      "Epoch [3820], val_loss: 3829.6750\n",
      "Epoch [3840], val_loss: 3874.6418\n",
      "Epoch [3860], val_loss: 3833.7927\n",
      "Epoch [3880], val_loss: 3814.9053\n",
      "Epoch [3900], val_loss: 3828.6055\n",
      "Epoch [3920], val_loss: 3826.7915\n",
      "Epoch [3940], val_loss: 3836.2632\n",
      "Epoch [3960], val_loss: 3803.9321\n",
      "Epoch [3980], val_loss: 3871.5737\n",
      "Epoch [4000], val_loss: 3877.9905\n",
      "Epoch [4020], val_loss: 3815.1455\n",
      "Epoch [4040], val_loss: 3830.0173\n",
      "Epoch [4060], val_loss: 3862.2490\n",
      "Epoch [4080], val_loss: 3846.7300\n",
      "Epoch [4100], val_loss: 3899.0151\n",
      "Epoch [4120], val_loss: 3805.1262\n",
      "Epoch [4140], val_loss: 3802.8047\n",
      "Epoch [4160], val_loss: 3875.1074\n",
      "Epoch [4180], val_loss: 3799.5000\n",
      "Epoch [4200], val_loss: 3815.9785\n",
      "Epoch [4220], val_loss: 3867.0737\n",
      "Epoch [4240], val_loss: 3937.3398\n",
      "Epoch [4260], val_loss: 3838.2380\n",
      "Epoch [4280], val_loss: 3838.6335\n",
      "Epoch [4300], val_loss: 3816.2214\n",
      "Epoch [4320], val_loss: 3867.3625\n",
      "Epoch [4340], val_loss: 3804.4087\n",
      "Epoch [4360], val_loss: 3807.3096\n",
      "Epoch [4380], val_loss: 3799.1194\n",
      "Epoch [4400], val_loss: 3855.3086\n",
      "Epoch [4420], val_loss: 3888.3774\n",
      "Epoch [4440], val_loss: 3820.9590\n",
      "Epoch [4460], val_loss: 3799.4458\n",
      "Epoch [4480], val_loss: 3839.7104\n",
      "Epoch [4500], val_loss: 3819.1829\n",
      "Epoch [4520], val_loss: 3817.6514\n",
      "Epoch [4540], val_loss: 3825.8245\n",
      "Epoch [4560], val_loss: 3816.9045\n",
      "Epoch [4580], val_loss: 3839.1416\n",
      "Epoch [4600], val_loss: 3850.0171\n",
      "Epoch [4620], val_loss: 3818.8794\n",
      "Epoch [4640], val_loss: 3852.8240\n",
      "Epoch [4660], val_loss: 3837.4851\n",
      "Epoch [4680], val_loss: 3804.6509\n",
      "Epoch [4700], val_loss: 3800.6450\n",
      "Epoch [4720], val_loss: 3859.7134\n",
      "Epoch [4740], val_loss: 3879.6538\n",
      "Epoch [4760], val_loss: 3813.8752\n",
      "Epoch [4780], val_loss: 3854.9250\n",
      "Epoch [4800], val_loss: 3839.6404\n",
      "Epoch [4820], val_loss: 3806.6465\n",
      "Epoch [4840], val_loss: 3854.5605\n",
      "Epoch [4860], val_loss: 3799.6091\n",
      "Epoch [4880], val_loss: 3824.5334\n",
      "Epoch [4900], val_loss: 3803.0640\n",
      "Epoch [4920], val_loss: 3843.7478\n",
      "Epoch [4940], val_loss: 3820.1321\n",
      "Epoch [4960], val_loss: 3803.9219\n",
      "Epoch [4980], val_loss: 3835.8923\n",
      "Epoch [5000], val_loss: 3800.3738\n",
      "Epoch [5020], val_loss: 3808.1431\n",
      "Epoch [5040], val_loss: 3868.2158\n",
      "Epoch [5060], val_loss: 3798.9863\n",
      "Epoch [5080], val_loss: 3810.7913\n",
      "Epoch [5100], val_loss: 3808.8105\n",
      "Epoch [5120], val_loss: 3831.5889\n"
     ]
    }
   ],
   "source": [
    "epochs = 5120\n",
    "lr = 0.1\n",
    "history2 = fit(epochs, lr, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20], val_loss: 3858.8059\n",
      "Epoch [40], val_loss: 3826.6509\n",
      "Epoch [60], val_loss: 3835.7273\n",
      "Epoch [80], val_loss: 3853.5774\n",
      "Epoch [100], val_loss: 3797.8125\n",
      "Epoch [120], val_loss: 3819.4927\n",
      "Epoch [140], val_loss: 3813.9976\n",
      "Epoch [160], val_loss: 3844.7734\n",
      "Epoch [180], val_loss: 3810.1311\n",
      "Epoch [200], val_loss: 3823.6023\n",
      "Epoch [220], val_loss: 3865.7068\n",
      "Epoch [240], val_loss: 3807.7388\n",
      "Epoch [260], val_loss: 3812.0000\n",
      "Epoch [280], val_loss: 3874.4880\n",
      "Epoch [300], val_loss: 3806.9336\n",
      "Epoch [320], val_loss: 3808.3618\n",
      "Epoch [340], val_loss: 3855.8096\n",
      "Epoch [360], val_loss: 3808.5547\n",
      "Epoch [380], val_loss: 3808.6965\n",
      "Epoch [400], val_loss: 3805.0415\n",
      "Epoch [420], val_loss: 3819.6077\n",
      "Epoch [440], val_loss: 3797.3159\n",
      "Epoch [460], val_loss: 3803.3674\n",
      "Epoch [480], val_loss: 3845.2202\n",
      "Epoch [500], val_loss: 3797.6353\n",
      "Epoch [520], val_loss: 3830.9939\n",
      "Epoch [540], val_loss: 3826.2803\n",
      "Epoch [560], val_loss: 3984.8394\n",
      "Epoch [580], val_loss: 3829.3159\n",
      "Epoch [600], val_loss: 3798.9238\n",
      "Epoch [620], val_loss: 3825.8335\n",
      "Epoch [640], val_loss: 3813.5771\n",
      "Epoch [660], val_loss: 3866.5640\n",
      "Epoch [680], val_loss: 3878.8794\n",
      "Epoch [700], val_loss: 3833.6677\n",
      "Epoch [720], val_loss: 3802.1399\n",
      "Epoch [740], val_loss: 3848.6108\n",
      "Epoch [760], val_loss: 3852.9294\n",
      "Epoch [780], val_loss: 3804.0549\n",
      "Epoch [800], val_loss: 3806.8918\n",
      "Epoch [820], val_loss: 3813.4712\n",
      "Epoch [840], val_loss: 3854.3738\n",
      "Epoch [860], val_loss: 3797.4695\n",
      "Epoch [880], val_loss: 3831.9963\n",
      "Epoch [900], val_loss: 3797.1826\n",
      "Epoch [920], val_loss: 3806.2141\n",
      "Epoch [940], val_loss: 3804.9451\n",
      "Epoch [960], val_loss: 3798.6462\n",
      "Epoch [980], val_loss: 3829.3135\n",
      "Epoch [1000], val_loss: 3815.7656\n",
      "Epoch [1020], val_loss: 3803.7683\n",
      "Epoch [1040], val_loss: 3829.8188\n",
      "Epoch [1060], val_loss: 3809.8259\n",
      "Epoch [1080], val_loss: 3842.0869\n",
      "Epoch [1100], val_loss: 3806.3557\n",
      "Epoch [1120], val_loss: 3801.6614\n",
      "Epoch [1140], val_loss: 3797.4092\n",
      "Epoch [1160], val_loss: 3838.4917\n",
      "Epoch [1180], val_loss: 3815.5171\n",
      "Epoch [1200], val_loss: 3804.4343\n",
      "Epoch [1220], val_loss: 3798.4751\n",
      "Epoch [1240], val_loss: 3812.0652\n",
      "Epoch [1260], val_loss: 3797.9561\n",
      "Epoch [1280], val_loss: 3816.9119\n",
      "Epoch [1300], val_loss: 3803.8853\n",
      "Epoch [1320], val_loss: 3843.8340\n",
      "Epoch [1340], val_loss: 3832.3694\n",
      "Epoch [1360], val_loss: 3879.2546\n",
      "Epoch [1380], val_loss: 3816.2607\n",
      "Epoch [1400], val_loss: 3855.0645\n",
      "Epoch [1420], val_loss: 3857.0425\n",
      "Epoch [1440], val_loss: 3815.9226\n",
      "Epoch [1460], val_loss: 3824.8398\n",
      "Epoch [1480], val_loss: 3826.2563\n",
      "Epoch [1500], val_loss: 3804.5615\n",
      "Epoch [1520], val_loss: 3826.0859\n",
      "Epoch [1540], val_loss: 3802.9412\n",
      "Epoch [1560], val_loss: 3840.5723\n",
      "Epoch [1580], val_loss: 3822.8872\n",
      "Epoch [1600], val_loss: 3797.8096\n",
      "Epoch [1620], val_loss: 3841.3418\n",
      "Epoch [1640], val_loss: 3842.8064\n",
      "Epoch [1660], val_loss: 3901.3618\n",
      "Epoch [1680], val_loss: 3797.4060\n",
      "Epoch [1700], val_loss: 3820.4060\n",
      "Epoch [1720], val_loss: 3810.0166\n",
      "Epoch [1740], val_loss: 3836.9849\n",
      "Epoch [1760], val_loss: 3875.3552\n",
      "Epoch [1780], val_loss: 3797.4124\n",
      "Epoch [1800], val_loss: 3840.6777\n",
      "Epoch [1820], val_loss: 3830.9504\n",
      "Epoch [1840], val_loss: 3811.7998\n",
      "Epoch [1860], val_loss: 3798.2969\n",
      "Epoch [1880], val_loss: 3814.7273\n",
      "Epoch [1900], val_loss: 3805.3154\n",
      "Epoch [1920], val_loss: 3796.9907\n",
      "Epoch [1940], val_loss: 3849.3936\n",
      "Epoch [1960], val_loss: 3814.5461\n",
      "Epoch [1980], val_loss: 3831.1987\n",
      "Epoch [2000], val_loss: 3898.4822\n",
      "Epoch [2020], val_loss: 3834.4072\n",
      "Epoch [2040], val_loss: 3865.5400\n",
      "Epoch [2060], val_loss: 3807.5625\n",
      "Epoch [2080], val_loss: 3962.1440\n",
      "Epoch [2100], val_loss: 3853.1489\n",
      "Epoch [2120], val_loss: 3797.4104\n",
      "Epoch [2140], val_loss: 3795.6550\n",
      "Epoch [2160], val_loss: 3797.9844\n",
      "Epoch [2180], val_loss: 3797.9131\n",
      "Epoch [2200], val_loss: 3859.9929\n",
      "Epoch [2220], val_loss: 3821.9595\n",
      "Epoch [2240], val_loss: 3799.6914\n",
      "Epoch [2260], val_loss: 3874.2583\n",
      "Epoch [2280], val_loss: 3796.5044\n",
      "Epoch [2300], val_loss: 3821.7014\n",
      "Epoch [2320], val_loss: 3827.8457\n",
      "Epoch [2340], val_loss: 3819.5378\n",
      "Epoch [2360], val_loss: 3807.8135\n",
      "Epoch [2380], val_loss: 3892.1912\n",
      "Epoch [2400], val_loss: 3796.0483\n",
      "Epoch [2420], val_loss: 3809.4075\n",
      "Epoch [2440], val_loss: 3849.7749\n",
      "Epoch [2460], val_loss: 3809.1780\n",
      "Epoch [2480], val_loss: 3890.1069\n",
      "Epoch [2500], val_loss: 3807.8003\n",
      "Epoch [2520], val_loss: 3830.8711\n",
      "Epoch [2540], val_loss: 3910.2422\n",
      "Epoch [2560], val_loss: 3876.0188\n",
      "Epoch [2580], val_loss: 3799.5100\n",
      "Epoch [2600], val_loss: 3823.2749\n",
      "Epoch [2620], val_loss: 3825.6418\n",
      "Epoch [2640], val_loss: 3825.3389\n",
      "Epoch [2660], val_loss: 3820.8718\n",
      "Epoch [2680], val_loss: 3864.0005\n",
      "Epoch [2700], val_loss: 3836.5715\n",
      "Epoch [2720], val_loss: 3814.6184\n",
      "Epoch [2740], val_loss: 3834.1694\n",
      "Epoch [2760], val_loss: 3803.2925\n",
      "Epoch [2780], val_loss: 3948.3740\n",
      "Epoch [2800], val_loss: 3804.7603\n",
      "Epoch [2820], val_loss: 3852.3459\n",
      "Epoch [2840], val_loss: 3808.7251\n",
      "Epoch [2860], val_loss: 3815.6953\n",
      "Epoch [2880], val_loss: 3797.3977\n",
      "Epoch [2900], val_loss: 3835.5596\n",
      "Epoch [2920], val_loss: 3921.8533\n",
      "Epoch [2940], val_loss: 3804.3840\n",
      "Epoch [2960], val_loss: 3795.0864\n",
      "Epoch [2980], val_loss: 3803.3726\n",
      "Epoch [3000], val_loss: 3873.5576\n",
      "Epoch [3020], val_loss: 3822.5049\n",
      "Epoch [3040], val_loss: 3797.1958\n",
      "Epoch [3060], val_loss: 3823.6572\n"
     ]
    }
   ],
   "source": [
    "epochs = 5120\n",
    "lr = 0.1\n",
    "history3 = fit(epochs, lr, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5120\n",
    "lr = 0.1\n",
    "history4 = fit(epochs, lr, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5120\n",
    "lr = 0.1\n",
    "history5 = fit(epochs, lr, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss = evaluate(model, val_loader)\n",
    "val_loss\n",
    "\n",
    "# NB! Valore di perdita altissimo, non riusciamo a ridurlo ulteriormente senza andare in overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single(input, target, model):\n",
    "    inputs = input.unsqueeze(0)\n",
    "    predictions = torch.max(model(inputs)).unsqueeze(0)\n",
    "    prediction = predictions[0].detach()\n",
    "    print(\"Input:\", input)\n",
    "    print(\"Target:\", target)\n",
    "    print(\"Prediction:\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input, target = val_ds[0]\n",
    "predict_single(input, target, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input, target = val_ds[10]\n",
    "predict_single(input, target, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input, target = val_ds[23]\n",
    "predict_single(input, target, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
